#!/usr/bin/env python3
"""
ä½¿ç”¨selfdebugæ¶æ„å¤„ç†defects4j-sfæ•°æ®é›†ä¸­çš„Javaä»£ç 
æ›¿ä»£SRepairä¸­çš„gen_solutionå’Œgen_patchï¼Œå¹¶ä½¿ç”¨sf_val_d4jéªŒè¯æ­£ç¡®ç‡
æ”¯æŒå¹¶è¡Œå¤„ç†å’Œç»Ÿè®¡ä¿®å¤æ­£ç¡®ç‡
"""

import json
import os
import time
import random
import argparse
import re
from typing import Dict, List, Optional, Tuple
from loguru import logger
import subprocess
import sys
from concurrent.futures import ProcessPoolExecutor, as_completed
import multiprocessing
from java_cfg_builder import JavaCFG
from utils import write_str_to_file
from chat import chat_java_fragment_debug

def slim_error_message(err_msg: str, token_limit: int = 200) -> str:
    """
    ç®€åŒ–error messageï¼Œç±»ä¼¼gen_solution_prompt.pyä¸­çš„slim_content_token
    Args:
        err_msg: åŸå§‹é”™è¯¯ä¿¡æ¯
        token_limit: tokené™åˆ¶
    Returns:
        ç®€åŒ–åçš„é”™è¯¯ä¿¡æ¯
    """
    err_msg_lines = err_msg.split('\n')
    slim_err_msg_lines = []
    current_tokens = 0
    
    for line in err_msg_lines:
        # ç®€å•ä¼°ç®—ï¼šä¸€ä¸ªå•è¯çº¦ç­‰äº1ä¸ªtoken
        line_tokens = len(line.split())
        if current_tokens + line_tokens > token_limit:
            break
        slim_err_msg_lines.append(line)
        current_tokens += line_tokens
    
    return '\n'.join(slim_err_msg_lines)

def extract_java_buggy_code(bug_data: Dict) -> str:
    """
    æå–Javaçš„buggyä»£ç 
    Args:
        bug_data: å•ä¸ªbugçš„æ•°æ®
    Returns:
        å®Œæ•´çš„buggyä»£ç 
    """
    buggy_code = bug_data['buggy']
    buggy_code_comment = bug_data.get('buggy_code_comment', '')
    
    # ç»„åˆæ³¨é‡Šå’Œä»£ç 
    if buggy_code_comment:
        full_code = buggy_code_comment + '\n' + buggy_code
    else:
        full_code = buggy_code
    
    return full_code

def extract_java_test_info(bug_data: Dict) -> Tuple[str, str]:
    """
    ä»trigger_testä¸­éšæœºé€‰æ‹©ä¸€ä¸ªæµ‹è¯•ç”¨ä¾‹å’Œé”™è¯¯ä¿¡æ¯ï¼ˆæŒ‰ç…§gen_solution_prompt.pyçš„æ–¹å¼ï¼‰
    Args:
        bug_data: å•ä¸ªbugçš„æ•°æ®
    Returns:
        (test_case, error_message) å…ƒç»„
    """
    trigger_tests = bug_data.get('trigger_test', {})
    
    # éšæœºé€‰æ‹©ä¸€ä¸ªtrigger testï¼ˆæŒ‰ç…§gen_solution_prompt.pyçš„æ–¹å¼ï¼‰
    if trigger_tests:
        random_trigger_test = random.choice(list(trigger_tests.keys()))
        selected_test = trigger_tests[random_trigger_test]
        test_case = selected_test.get('src', '')
        error_message = selected_test.get('clean_error_msg', '')
        
        if error_message:
            error_message = slim_error_message(error_message)
        
        return test_case, error_message
    
    return "", ""

def selfdebug_java_single(bug_name: str, bug_data: Dict) -> Optional[str]:
    """
    ä½¿ç”¨é™æ€åˆ†ææ–¹æ³•å¤„ç†å•ä¸ªJava bug
    Args:
        bug_name: bugåç§°
        bug_data: bugæ•°æ®
    Returns:
        ä¿®å¤åçš„ä»£ç ï¼Œå¤±è´¥æ—¶è¿”å›None
    """
    logger.info(f"Processing bug: {bug_name}")
    
    # æå–åŸºæœ¬ä¿¡æ¯
    buggy_code = extract_java_buggy_code(bug_data)
    test_case, error_message = extract_java_test_info(bug_data)
    
    logger.info(f"Buggy code length: {len(buggy_code)}")
    logger.info(f"Buggy code: {buggy_code}")
    logger.info(f"Test case length: {len(test_case)}")
    logger.info(f"Test case: {test_case}")
    logger.info(f"Error message length: {len(error_message)}")
    logger.info(f"Error message: {error_message}")
    
    # æ„å»ºCFG - ä½¿ç”¨Java CFG builder
    cfg_text = ""
    try:
        # åˆ›å»ºä¸´æ—¶Javaæ–‡ä»¶
        temp_filename = f"temp_java_{bug_name.replace('-', '_')}.java"
        
        # æ£€æŸ¥ä»£ç æ˜¯å¦åŒ…å«ç±»å®šä¹‰ï¼Œå¦‚æœæ²¡æœ‰åˆ™åŒ…è£…åœ¨ä¸´æ—¶ç±»ä¸­
        java_code_to_write = buggy_code
        if not re.search(r'\bclass\s+\w+', buggy_code):
            # æ²¡æœ‰ç±»å®šä¹‰ï¼ŒåŒ…è£…åœ¨ä¸´æ—¶ç±»ä¸­
            java_code_to_write = f"""
            public class TempClass {{
            {buggy_code}
            }}
            """
            logger.info(f"Wrapped method in temporary class for {bug_name}")
        
        write_str_to_file(java_code_to_write, temp_filename)
        
        # ä½¿ç”¨JavaCFGæ„å»ºæ§åˆ¶æµå›¾
        java_cfg = JavaCFG(temp_filename)
        cfg_text = java_cfg.cfg_text
        logger.info(f"CFG text: {cfg_text}")
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if os.path.exists(temp_filename):
            os.remove(temp_filename)
            
        logger.info(f"CFG built successfully for {bug_name}")
        
    except Exception as e:
        logger.warning(f"CFG construction failed for {bug_name}: {e}")
        cfg_text = ""
    
    # ä½¿ç”¨é™æ€åˆ†ææ–¹æ³•è¿›è¡Œè°ƒè¯•
    try:
        logger.info(f"Starting static analysis debug for {bug_name}")
        
        # å¦‚æœæ²¡æœ‰æµ‹è¯•ç”¨ä¾‹æˆ–é”™è¯¯ä¿¡æ¯ï¼Œä½¿ç”¨å ä½ç¬¦
        if not test_case:
            test_case = "No specific test case available"
        if not error_message:
            error_message = "No specific error message available"
            
        debug_result = chat_java_fragment_debug(
            buggy_code=buggy_code,
            error_message=error_message,
            test_case=test_case,
            cfg_text=cfg_text
        )
        
        # æ‰“å°åŸå§‹å“åº”ç”¨äºè°ƒè¯•
        logger.info(f"Raw LLM response for {bug_name}:")
        logger.info(f"Response length: {len(debug_result)}")
        logger.info(f"First 500 chars: {debug_result}")
        
        # é¢„å¤„ç†å“åº”ï¼Œå»æ‰markdownä»£ç å—æ ‡è®°
        processed_result = debug_result.strip()
        if processed_result.startswith("```json"):
            processed_result = processed_result[7:]  # å»æ‰```json
        if processed_result.endswith("```"):
            processed_result = processed_result[:-3]  # å»æ‰```
        processed_result = processed_result.strip()
        
        # è§£æç»“æœ
        try:
            debug_json = json.loads(processed_result)
            corrected_code = debug_json.get("corrected_code", buggy_code)
            explanation = debug_json.get("explanation", "No explanation provided")
            
            logger.info(f"Debug completed for {bug_name}")
            logger.info(f"Corrected code: {corrected_code}")
            logger.info(f"Explanation: {explanation}")
            
            # æ£€æŸ¥æ˜¯å¦ç”Ÿæˆäº†ä¿®å¤ä»£ç ï¼ˆä¸ç®¡æ˜¯å¦æ­£ç¡®ï¼Œéƒ½éœ€è¦éªŒè¯ï¼‰
            if corrected_code and corrected_code.strip() != buggy_code.strip():
                logger.info(f"ğŸ“ Generated patch for {bug_name} (needs validation)")
                return corrected_code
            else:
                logger.warning(f"âŒ No patch generated for {bug_name}")
                return None
                
        except json.JSONDecodeError as e:
            logger.warning(f"JSON parse error for {bug_name}: {e}")
            logger.warning(f"Trying to extract code from non-JSON response...")
            
            # å°è¯•ä»åŸå§‹å“åº”ä¸­æå–ä»£ç 
            if "```java" in debug_result:
                start = debug_result.find("```java") + 7
                end = debug_result.find("```", start)
                if end > start:
                    extracted_code = debug_result[start:end].strip()
                    if extracted_code and extracted_code != buggy_code.strip():
                        logger.info(f"ğŸ“ Extracted patch from non-JSON response for {bug_name} (needs validation)")
                        return extracted_code
            
            logger.warning(f"âŒ Could not extract any meaningful fix for {bug_name}")
            return None
            
    except Exception as e:
        logger.error(f"Static analysis debug failed for {bug_name}: {e}")
        return None

def process_single_bug_task(task_data: Tuple[str, Dict]) -> Tuple[str, Optional[str], bool]:
    """
    å¹¶è¡Œå¤„ç†å•ä¸ªbugä»»åŠ¡
    Args:
        task_data: (bug_name, bug_data) å…ƒç»„
    Returns:
        (bug_name, corrected_code, success) å…ƒç»„
    """
    bug_name, bug_data = task_data
    
    try:
        corrected_code = selfdebug_java_single(bug_name, bug_data)
        success = corrected_code is not None and corrected_code.strip() != bug_data['buggy'].strip()
        return bug_name, corrected_code, success
    except Exception as e:
        logger.error(f"Error processing {bug_name}: {e}")
        return bug_name, None, False

def process_defects4j_dataset_parallel(dataset_path: str, output_path: str, limit: int = None, max_workers: int = None) -> Dict:
    """
    å¹¶è¡Œå¤„ç†æ•´ä¸ªdefects4jæ•°æ®é›†
    Args:
        dataset_path: æ•°æ®é›†è·¯å¾„
        output_path: è¾“å‡ºè·¯å¾„
        limit: é™åˆ¶å¤„ç†çš„bugæ•°é‡
        max_workers: æœ€å¤§å¹¶è¡Œworkeræ•°é‡
    Returns:
        å¤„ç†ç»“æœå­—å…¸
    """
    logger.info(f"Loading dataset from {dataset_path}")
    
    with open(dataset_path, 'r', encoding='utf-8') as f:
        dataset = json.load(f)
    
    total_bugs = len(dataset)
    logger.info(f"Total bugs in dataset: {total_bugs}")
    
    bug_names = list(dataset.keys())
    
    # å¦‚æœè®¾ç½®äº†é™åˆ¶ï¼Œåªå¤„ç†æŒ‡å®šæ•°é‡çš„bugs
    if limit is not None and limit > 0:
        bug_names = bug_names[:limit]
        logger.info(f"Limited processing to first {limit} bugs")
    
    # è®¾ç½®å¹¶è¡Œworkeræ•°é‡
    if max_workers is None:
        max_workers = min(multiprocessing.cpu_count(), len(bug_names))
    
    logger.info(f"Using {max_workers} parallel workers")
    
    # å‡†å¤‡ä»»åŠ¡æ•°æ®
    tasks = [(bug_name, dataset[bug_name]) for bug_name in bug_names]
    
    results = {}
    patches_generated = 0
    successful_fixes = 0
    
    # å¹¶è¡Œå¤„ç†
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        future_to_bug = {executor.submit(process_single_bug_task, task): task[0] for task in tasks}
        
        # æ”¶é›†ç»“æœ
        for i, future in enumerate(as_completed(future_to_bug), 1):
            bug_name = future_to_bug[future]
            
            try:
                bug_name_result, corrected_code, success = future.result()
                
                logger.info(f"=== Completed bug {i}/{len(bug_names)}: {bug_name_result} ===")
                
                if corrected_code and corrected_code != dataset[bug_name_result]['buggy']:
                    results[bug_name_result] = {
                        'patches': [corrected_code],
                        'original_buggy': dataset[bug_name_result]['buggy'],
                        'bug_info': {
                            'loc': dataset[bug_name_result]['loc'],
                            'start': dataset[bug_name_result]['start'],
                            'end': dataset[bug_name_result]['end']
                        },
                        'patch_generated': True
                    }
                    patches_generated += 1
                    if success:
                        successful_fixes += 1
                    logger.info(f"ğŸ“ Generated patch for {bug_name_result} (validation required)")
                else:
                    logger.warning(f"âŒ No patch generated for {bug_name_result}")
                    # ä¸ºäº†èƒ½å¤Ÿè¿›è¡ŒéªŒè¯ï¼Œå³ä½¿å¤±è´¥ä¹Ÿè¦è®°å½•åŸå§‹ä»£ç 
                    results[bug_name_result] = {
                        'patches': [dataset[bug_name_result]['buggy']],  # ä½¿ç”¨åŸå§‹ä»£ç 
                        'original_buggy': dataset[bug_name_result]['buggy'],
                        'bug_info': {
                            'loc': dataset[bug_name_result]['loc'],
                            'start': dataset[bug_name_result]['start'],
                            'end': dataset[bug_name_result]['end']
                        },
                        'patch_generated': False
                    }
                
                # å®šæœŸä¿å­˜ä¸­é—´ç»“æœ
                if i % 10 == 0:
                    logger.info(f"Progress: {i}/{len(bug_names)} completed, saving intermediate results...")
                    with open(output_path, 'w', encoding='utf-8') as f:
                        json.dump(results, f, indent=2, ensure_ascii=False)
                        
            except Exception as e:
                logger.error(f"Error processing result for {bug_name}: {e}")
                # è®°å½•å¤±è´¥çš„æƒ…å†µ
                results[bug_name] = {
                    'patches': [dataset[bug_name]['buggy']],  # ä½¿ç”¨åŸå§‹ä»£ç 
                    'original_buggy': dataset[bug_name]['buggy'],
                    'bug_info': {
                        'loc': dataset[bug_name]['loc'],
                        'start': dataset[bug_name]['start'],
                        'end': dataset[bug_name]['end']
                    },
                    'patch_generated': False
                }
    
    logger.info(f"=== Parallel processing completed ===")
    logger.info(f"Total processed: {len(bug_names)}")
    logger.info(f"Patches generated: {patches_generated}")
    logger.info(f"Patch generation rate: {patches_generated/len(bug_names)*100:.2f}%")
    
    # ä¿å­˜æœ€ç»ˆç»“æœ
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    logger.info(f"Results saved to {output_path}")
    return results

def run_validation(patch_file: str, dataset_path: str, output_dir: str):
    """
    è¿è¡Œsf_val_d4jéªŒè¯ï¼Œæ˜¾ç¤ºå®æ—¶è¿›åº¦
    Args:
        patch_file: è¡¥ä¸æ–‡ä»¶è·¯å¾„
        dataset_path: æ•°æ®é›†è·¯å¾„
        output_dir: è¾“å‡ºç›®å½•
    """
    logger.info("Starting validation with sf_val_d4j...")
    
    # æ„å»ºéªŒè¯å‘½ä»¤
    val_script = "dataset_test/SRepair/SRepair/src/sf_val_d4j.py"
    
    if not os.path.exists(val_script):
        logger.error(f"Validation script not found: {val_script}")
        return
    
    # è¯»å–è¡¥ä¸æ–‡ä»¶è·å–æ€»æ•°é‡ä»¥æ˜¾ç¤ºè¿›åº¦
    try:
        with open(patch_file, 'r', encoding='utf-8') as f:
            patches_data = json.load(f)
        total_bugs = len(patches_data)
        logger.info(f"ğŸ“Š Total bugs to validate: {total_bugs}")
    except Exception as e:
        logger.error(f"Error reading patch file: {e}")
        total_bugs = 0
    
    cmd = [
        sys.executable, val_script,
        '-i', patch_file,
        '-d', dataset_path,
        '-o', output_dir
    ]
    
    logger.info(f"Running validation command: {' '.join(cmd)}")
    
    try:
        # å¯åŠ¨éªŒè¯è¿›ç¨‹å¹¶å®æ—¶æ˜¾ç¤ºè¾“å‡º
        process = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, 
                                 text=True, bufsize=1, universal_newlines=True)
        
        # å¯åŠ¨è¿›åº¦ç›‘æ§çº¿ç¨‹
        import threading
        stop_monitoring = threading.Event()
        monitor_thread = threading.Thread(target=monitor_validation_progress, 
                                        args=(output_dir, total_bugs, stop_monitoring))
        monitor_thread.daemon = True
        monitor_thread.start()
        
        # å®æ—¶è¾“å‡ºéªŒè¯æ—¥å¿—
        while True:
            output = process.stdout.readline()
            if output == '' and process.poll() is not None:
                break
            if output:
                # è¿‡æ»¤å’Œæ ¼å¼åŒ–è¾“å‡º
                line = output.strip()
                if line:
                    if '[PATCH STATUS]' in line:
                        logger.info(f"ğŸ” {line}")
                    elif '[TIME INFO]' in line:
                        logger.info(f"â±ï¸ {line}")
                    elif '[CHECKOUT]' in line:
                        logger.info(f"ğŸ“¦ {line}")
                    elif 'END VALIDATION' in line:
                        logger.info(f"âœ… {line}")
                    else:
                        logger.debug(f"[VAL] {line}")
        
        # åœæ­¢ç›‘æ§å¹¶ç­‰å¾…è¿›ç¨‹å®Œæˆ
        stop_monitoring.set()
        return_code = process.wait()
        
        if return_code == 0:
            logger.info("âœ… Validation completed successfully!")
            logger.info(f"ğŸ“ Results saved to: {output_dir}")
        else:
            logger.error(f"âŒ Validation failed with return code {return_code}")
            
    except subprocess.TimeoutExpired:
        logger.error("âŒ Validation timed out after 1 hour")
    except Exception as e:
        logger.error(f"âŒ Error running validation: {e}")

def monitor_validation_progress(output_dir: str, total_bugs: int, stop_event):
    """
    ç›‘æ§éªŒè¯è¿›åº¦
    """
    import time
    
    if total_bugs == 0:
        return
    
    start_time = time.time()
    last_count = 0
    
    while not stop_event.is_set():
        try:
            if not os.path.exists(output_dir):
                time.sleep(5)
                continue
            
            # ç»Ÿè®¡å·²å®Œæˆçš„éªŒè¯æ–‡ä»¶
            import glob
            completed_files = glob.glob(os.path.join(output_dir, '*-validated.jsonl'))
            completed_count = len(completed_files)
            
            if completed_count > last_count:
                elapsed_time = time.time() - start_time
                progress_percent = (completed_count / total_bugs) * 100
                
                if completed_count > 0:
                    avg_time_per_bug = elapsed_time / completed_count
                    remaining_bugs = total_bugs - completed_count
                    eta_seconds = avg_time_per_bug * remaining_bugs
                    eta_minutes = eta_seconds / 60
                    
                    logger.info(f"ğŸ“ˆ Progress: {completed_count}/{total_bugs} ({progress_percent:.1f}%) "
                              f"| Elapsed: {elapsed_time/60:.1f}m | ETA: {eta_minutes:.1f}m")
                
                last_count = completed_count
            
            if completed_count >= total_bugs:
                break
                
            time.sleep(15)  # æ¯15ç§’æ£€æŸ¥ä¸€æ¬¡
            
        except Exception as e:
            logger.debug(f"Progress monitoring error: {e}")
            time.sleep(15)

def parse_validation_results(validation_output_dir: str) -> Dict:
    """
    è§£æéªŒè¯ç»“æœå¹¶ç»Ÿè®¡ä¿®å¤æ­£ç¡®ç‡
    Args:
        validation_output_dir: éªŒè¯ç»“æœè¾“å‡ºç›®å½•
    Returns:
        ç»Ÿè®¡ç»“æœå­—å…¸
    """
    logger.info(f"Parsing validation results from {validation_output_dir}")
    
    if not os.path.exists(validation_output_dir):
        logger.error(f"Validation output directory not found: {validation_output_dir}")
        return {}
    
    validation_files = [f for f in os.listdir(validation_output_dir) if f.endswith('-validated.jsonl')]
    
    total_bugs = 0
    plausible_fixes = 0
    correct_fixes = 0
    uncompilable_fixes = 0
    timeout_fixes = 0
    
    detailed_results = {}
    
    for val_file in validation_files:
        val_file_path = os.path.join(validation_output_dir, val_file)
        bug_name = val_file.replace('-validated.jsonl', '')
        
        try:
            with open(val_file_path, 'r', encoding='utf-8') as f:
                bug_results = json.load(f)
            
            for patch_result in bug_results:
                total_bugs += 1
                status = patch_result.get('patch_status', 'UNKNOWN')
                
                detailed_results[f"{bug_name}_patch_{patch_result.get('val_cnt', 1)}"] = {
                    'bug_name': bug_name,
                    'status': status,
                    'failing_tests': patch_result.get('failing_tests', {}),
                    'patch_code': patch_result.get('patch_code', '')[:100] + '...'  # åªä¿ç•™å‰100å­—ç¬¦
                }
                
                if status == 'PLAUSIBLE':
                    plausible_fixes += 1
                    correct_fixes += 1  # PLAUSIBLE è¡¨ç¤ºé€šè¿‡äº†æ‰€æœ‰æµ‹è¯•
                elif status == 'UNCOMPILABLE':
                    uncompilable_fixes += 1
                elif 'TIMEOUT' in status:
                    timeout_fixes += 1
        
        except Exception as e:
            logger.error(f"Error parsing validation file {val_file}: {e}")
            continue
    
    # è®¡ç®—ç»Ÿè®¡ç»“æœ
    patch_generation_rate = 0
    plausible_rate = 0
    correct_rate = 0
    
    if total_bugs > 0:
        plausible_rate = (plausible_fixes / total_bugs) * 100
        correct_rate = (correct_fixes / total_bugs) * 100
    
    statistics = {
        'total_bugs_validated': total_bugs,
        'plausible_fixes': plausible_fixes,
        'correct_fixes': correct_fixes,
        'uncompilable_fixes': uncompilable_fixes,
        'timeout_fixes': timeout_fixes,
        'other_fixes': total_bugs - plausible_fixes - uncompilable_fixes - timeout_fixes,
        'plausible_rate': round(plausible_rate, 2),
        'correct_rate': round(correct_rate, 2),
        'detailed_results': detailed_results
    }
    
    # æ‰“å°ç»Ÿè®¡ç»“æœ
    logger.info("=== DEFECTS4J REPAIR STATISTICS ===")
    logger.info(f"Total bugs validated: {total_bugs}")
    logger.info(f"Plausible fixes: {plausible_fixes}")
    logger.info(f"Correct fixes: {correct_fixes}")
    logger.info(f"Uncompilable fixes: {uncompilable_fixes}")
    logger.info(f"Timeout fixes: {timeout_fixes}")
    logger.info(f"Other status fixes: {statistics['other_fixes']}")
    logger.info(f"Plausible rate: {plausible_rate:.2f}%")
    logger.info(f"Correct rate: {correct_rate:.2f}%")
    logger.info("=" * 40)
    
    return statistics

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="Use static analysis architecture to process defects4j dataset")
    parser.add_argument('--dataset', '-d', type=str, 
                       default='dataset_test/SRepair/SRepair/dataset/defects4j-sf.json',
                       help='Path to defects4j-sf.json dataset')
    parser.add_argument('--output', '-o', type=str,
                       default='dataset_test/SRepair/results/sf/defects4j_corrected_code_patches.json',
                       help='Output path for generated patches')
    parser.add_argument('--validate', '-v', action='store_true',
                       help='Run validation after generating patches')
    parser.add_argument('--validate-only', action='store_true',
                       help='Only run validation on existing patch file (skip patch generation)')
    parser.add_argument('--val-output', type=str, default='dataset_test/SRepair/results/sf/defects4j_validation_results',
                       help='Output directory for validation results')
    parser.add_argument('--limit', '-l', type=int, default=None,
                       help='Limit the number of bugs to process (useful for debugging)')
    parser.add_argument('--workers', '-w', type=int, default=None,
                       help='Number of parallel workers (default: CPU count)')
    parser.add_argument('--parse-results', action='store_true',
                       help='Only parse existing validation results and show statistics')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logger.info("Starting defects4j static analysis processing...")
    logger.info(f"Dataset: {args.dataset}")
    logger.info(f"Output: {args.output}")
    logger.info(f"Validate: {args.validate}")
    logger.info(f"Validate only: {args.validate_only}")
    if args.limit:
        logger.info(f"Processing limit: {args.limit} bugs")
    if args.workers:
        logger.info(f"Parallel workers: {args.workers}")
    
    # å¦‚æœåªæ˜¯è§£æç»“æœï¼Œç›´æ¥è§£æå¹¶é€€å‡º
    if args.parse_results:
        logger.info("ğŸ” Parsing existing validation results...")
        statistics = parse_validation_results(args.val_output)
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats_file = os.path.join(os.path.dirname(args.output), 'repair_statistics.json')
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(statistics, f, indent=2, ensure_ascii=False)
        logger.info(f"Statistics saved to {stats_file}")
        return
    
    # å¦‚æœåªæ˜¯éªŒè¯ç°æœ‰è¡¥ä¸
    if args.validate_only:
        logger.info("ğŸ” Validating existing patches only...")
        
        # æ£€æŸ¥è¡¥ä¸æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(args.output):
            logger.error(f"Patch file not found: {args.output}")
            logger.error("Please generate patches first or specify correct patch file path with --output")
            return
        
        # åˆ é™¤ç°æœ‰è¾“å‡ºç›®å½•ä»¥é¿å…å†²çª
        if os.path.exists(args.val_output):
            import shutil
            logger.info(f"Removing existing validation output directory: {args.val_output}")
            shutil.rmtree(args.val_output)
        
        # ç›´æ¥è¿è¡ŒéªŒè¯
        run_validation(args.output, args.dataset, args.val_output)
        
        # è§£æéªŒè¯ç»“æœ
        logger.info("ğŸ” Parsing validation results and calculating repair rates...")
        time.sleep(5)  # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
        
        statistics = parse_validation_results(args.val_output)
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats_file = os.path.join(os.path.dirname(args.output), 'repair_statistics.json')
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(statistics, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š Repair statistics saved to {stats_file}")
        logger.info("Validation completed!")
        return
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.dataset):
        logger.error(f"Dataset file not found: {args.dataset}")
        return
    
    # å¤„ç†æ•°æ®é›†
    start_time = time.time()
    results = process_defects4j_dataset_parallel(args.dataset, args.output, args.limit, args.workers)
    processing_time = time.time() - start_time
    
    logger.info(f"Patch generation completed in {processing_time:.2f} seconds")
    
    # è¿è¡ŒéªŒè¯
    if args.validate:
        logger.info("ğŸ” Starting validation with sf_val_d4j...")
        
        # åˆ é™¤ç°æœ‰è¾“å‡ºç›®å½•ä»¥é¿å…å†²çª
        if os.path.exists(args.val_output):
            import shutil
            logger.info(f"Removing existing validation output directory: {args.val_output}")
            shutil.rmtree(args.val_output)
        
        run_validation(args.output, args.dataset, args.val_output)
        
        # ç­‰å¾…éªŒè¯å®Œæˆåè§£æç»“æœ
        logger.info("ğŸ” Parsing validation results and calculating repair rates...")
        time.sleep(5)  # ç­‰å¾…æ–‡ä»¶å†™å…¥å®Œæˆ
        
        statistics = parse_validation_results(args.val_output)
        
        # ä¿å­˜ç»Ÿè®¡ç»“æœ
        stats_file = os.path.join(os.path.dirname(args.output), 'repair_statistics.json')
        with open(stats_file, 'w', encoding='utf-8') as f:
            json.dump(statistics, f, indent=2, ensure_ascii=False)
        
        logger.info(f"ğŸ“Š Repair statistics saved to {stats_file}")
        
    else:
        logger.info("ğŸ” To validate patches, run with --validate flag")
        logger.info("ğŸ’¡ Example: python self_debug_multi_defects4j.py --validate --workers 4")
        logger.info("ğŸ’¡ Or validate existing patches: python self_debug_multi_defects4j.py --validate-only")
    
    logger.info("All tasks completed!")

if __name__ == "__main__":
    # main() 
    bug_name = "Jsoup-39"
    bug_data = json.load(open("dataset_test/SRepair/SRepair/dataset/defects4j-sf.json", "r"))[bug_name]
    selfdebug_java_single(bug_name, bug_data)
